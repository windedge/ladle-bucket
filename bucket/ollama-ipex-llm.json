{
    "homepage": "https://github.com/ipex-llm/ipex-llm",
    "description": "IPEX-LLM (Intel Extension for PyTorch) nightly build with llama.cpp - Generic Windows version",
    "license": "MIT",
    "version": "2.3.0b20250612",
    "architecture": {
        "64bit": {
            "url": "https://github.com/ipex-llm/ipex-llm/releases/download/v2.3.0-nightly/ollama-ipex-llm-2.3.0b20250612-win.zip",
            "hash": "7df3570affcd35b3fc63e9998564cd111f452d12a6f9ab63c69f0274932f5f44"
        }
    },
    "bin": [
        "ollama.exe",
        "ollama-lib.exe",
        "ollama-serve.bat",
        "start-ollama.bat"
    ],
    "checkver": {
        "url": "https://api.github.com/repos/ipex-llm/ipex-llm/releases",
        "regex": "https://github\\.com/ipex-llm/ipex-llm/releases/download/([^/]+)/ollama-ipex-llm-([\\d\\.]+.?\\d+)-win\\.zip",
        "replace": "${2}"
    },
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://github.com/ipex-llm/ipex-llm/releases/download/$match1/ollama-ipex-llm-$match2-win.zip"
            }
        }
    }
}
