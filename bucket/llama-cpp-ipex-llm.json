{
    "homepage": "https://github.com/intel/ipex-llm",
    "description": "IPEX-LLM (Intel Extension for PyTorch) nightly build with llama.cpp - Generic Windows version",
    "license": "MIT",
    "version": "2.2.0b20250313",
    "architecture": {
        "64bit": {
            "url": "https://github.com/intel/ipex-llm/releases/download/v2.2.0-nightly/llama-cpp-ipex-llm-2.2.0b20250313-win.zip",
            "hash": "b216d796dc975fe42de44425eecb6ebb4d9c973c9a49afcf4e6aec87244bca55"
        }
    },
    "bin": [
        "llama-batched.exe",
        "llama-bench.exe",
        "llama-cli.exe",
        "llama-embedding.exe",
        "llama-gemma3-cli.exe",
        "llama-gguf.exe",
        "llama-llava-cli.exe",
        "llama-lookup.exe",
        "llama-ls-sycl-device.exe",
        "llama-minicpmv-cli.exe",
        "llama-perplexity.exe",
        "llama-quantize.exe",
        "llama-server.exe",
        "llama-simple.exe",
        "llama-speculative.exe",
        "llama-tokenize.exe"
    ],
    "checkver": {
        "url": "https://api.github.com/repos/intel/ipex-llm/releases",
        "regex": "https://github\\.com/intel/ipex-llm/releases/download/([^/]+)/llama-cpp-ipex-llm-([\\d\\.]+b\\d+)-win\\.zip",
        "replace": "${2}"
    },
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://github.com/intel/ipex-llm/releases/download/$match1/llama-cpp-ipex-llm-$match2-win.zip"
            }
        }
    }
}
